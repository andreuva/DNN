{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NOTEBOOK FOR TRAINING THE MODEL WITH RESNET ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:56:17.082810: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/avicente/Documents/envs/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# IMPORT THE MODULES NEEDED\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.python.keras.utils import losses_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.preprocessing import normalize\n",
    "from classification_models.tfkeras import Classifiers\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "# Use only one GPU, comment this out for using all GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the parameters of the network and the save/log/data directories\n",
    "# Change parameters here...\n",
    "sizex = 128                 # 128 x\n",
    "sizey = 128                 # 128 pixels\n",
    "sizez = 3                   # 3 color channels: RGB\n",
    "rand_seed = 666             # Seed for random processes\n",
    "batch_size = 32 * 2         # Size of batches passed to the GPU(s)\n",
    "nb_epochs = 100             # Number of epochs for training\n",
    "validation_ratio = 0.2      #Ratio of dataset used as validation\n",
    "use_dust = False            # Parameter to also use images with dust rendered\n",
    "log_dir = \"../data/DNN/logs/\"        # Where log files will be saved\n",
    "data_dir = '../data/DNN/data/'       # Where data is stored\n",
    "resnet_select = 'resnet18'  # Define the desired resnet model\n",
    "\n",
    "# Ensure log file directory\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Propare output filenames\n",
    "model_name = resnet_select + '_bs' + str(batch_size)\n",
    "if use_dust: model_name += '_dust'\n",
    "snapshot_weights = 'models/best_'+model_name+'.hdf5'\n",
    "last_snapshot_weights = 'models/last_'+model_name+'.hdf5'\n",
    "json_name = 'models/json_'+model_name+'.json'\n",
    "trained_model = 'models/trained_'+model_name+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: Use negative log likelihood for a PDF output\n",
    "negloglik = lambda y, p_y: -p_y.log_prob(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:56:19.813286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Num GPUs Available:  1\n",
      "Number of devices: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:56:19.845151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:56:19.845501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:56:19.846802: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-26 10:56:19.847636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:56:19.848149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:56:19.848574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:56:20.370672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:56:20.371015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:56:20.371295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:56:20.371535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2618 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "# Define the strategy and check GPUs available\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Defining the model in all the devices (GPU's) available\n",
    "# import the prefdefined model\n",
    "ResNet, preprocess_input = Classifiers.get(resnet_select)\n",
    "\n",
    "# Build the model\n",
    "with strategy.scope():\n",
    "    # Image classification network\n",
    "    model = ResNet(input_shape=(sizex, sizey, sizez), include_top=False)\n",
    "\n",
    "    # Resizing (Pooling) and bottle neck\n",
    "    globavg = tf.keras.layers.GlobalAveragePooling2D()(model.layers[-1].output)\n",
    "    dense1 = tf.keras.layers.Dense(512, activation=tf.nn.leaky_relu)(globavg)\n",
    "    drop1 =  tf.keras.layers.Dropout(rate = 0.2)(dense1)\n",
    "    dense2 = tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu)(drop1)\n",
    "    drop2 =  tf.keras.layers.Dropout(rate = 0.2)(dense2)\n",
    "    dense3 = tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu)(drop2)\n",
    "    drop3 =  tf.keras.layers.Dropout(rate = 0.2)(dense3)\n",
    "    dense4 = tf.keras.layers.Dense(2)(drop3)\n",
    "    \n",
    "    # Change the output to a normal PDF. Remember to set a layer with \n",
    "    # 2 neurons (mean and std) before it\n",
    "    output = tfpl.IndependentNormal(event_shape=1)(dense4)\n",
    " \n",
    "    model = tf.keras.models.Model(inputs=model.inputs, outputs=output)\n",
    "    \n",
    "    # Compile the model specifying the optimazer (sgd) and the loss function and other metrics\n",
    "    model.compile(optimizer= tf.keras.optimizers.SGD(),\n",
    "                  loss= negloglik, metrics=[\n",
    "                                                       tf.keras.metrics.mean_absolute_error,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data (InputLayer)              [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " bn_data (BatchNormalization)   (None, 128, 128, 3)  9           ['data[0][0]']                   \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 134, 134, 3)  0          ['bn_data[0][0]']                \n",
      "                                                                                                  \n",
      " conv0 (Conv2D)                 (None, 64, 64, 64)   9408        ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " bn0 (BatchNormalization)       (None, 64, 64, 64)   256         ['conv0[0][0]']                  \n",
      "                                                                                                  \n",
      " relu0 (Activation)             (None, 64, 64, 64)   0           ['bn0[0][0]']                    \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 66, 66, 64)  0           ['relu0[0][0]']                  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " pooling0 (MaxPooling2D)        (None, 32, 32, 64)   0           ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit1_bn1 (BatchNormali  (None, 32, 32, 64)  256         ['pooling0[0][0]']               \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu1 (Activation  (None, 32, 32, 64)  0           ['stage1_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadding2  (None, 34, 34, 64)  0           ['stage1_unit1_relu1[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage1_unit1_conv1 (Conv2D)    (None, 32, 32, 64)   36864       ['zero_padding2d_2[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit1_bn2 (BatchNormali  (None, 32, 32, 64)  256         ['stage1_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu2 (Activation  (None, 32, 32, 64)  0           ['stage1_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadding2  (None, 34, 34, 64)  0           ['stage1_unit1_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage1_unit1_conv2 (Conv2D)    (None, 32, 32, 64)   36864       ['zero_padding2d_3[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit1_sc (Conv2D)       (None, 32, 32, 64)   4096        ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 64)   0           ['stage1_unit1_conv2[0][0]',     \n",
      "                                                                  'stage1_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage1_unit2_bn1 (BatchNormali  (None, 32, 32, 64)  256         ['add[0][0]']                    \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu1 (Activation  (None, 32, 32, 64)  0           ['stage1_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 34, 34, 64)  0           ['stage1_unit2_relu1[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage1_unit2_conv1 (Conv2D)    (None, 32, 32, 64)   36864       ['zero_padding2d_4[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit2_bn2 (BatchNormali  (None, 32, 32, 64)  256         ['stage1_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu2 (Activation  (None, 32, 32, 64)  0           ['stage1_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadding2  (None, 34, 34, 64)  0           ['stage1_unit2_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage1_unit2_conv2 (Conv2D)    (None, 32, 32, 64)   36864       ['zero_padding2d_5[0][0]']       \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 64)   0           ['stage1_unit2_conv2[0][0]',     \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " stage2_unit1_bn1 (BatchNormali  (None, 32, 32, 64)  256         ['add_1[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu1 (Activation  (None, 32, 32, 64)  0           ['stage2_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadding2  (None, 34, 34, 64)  0           ['stage2_unit1_relu1[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit1_conv1 (Conv2D)    (None, 16, 16, 128)  73728       ['zero_padding2d_6[0][0]']       \n",
      "                                                                                                  \n",
      " stage2_unit1_bn2 (BatchNormali  (None, 16, 16, 128)  512        ['stage2_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu2 (Activation  (None, 16, 16, 128)  0          ['stage2_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadding2  (None, 18, 18, 128)  0          ['stage2_unit1_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit1_conv2 (Conv2D)    (None, 16, 16, 128)  147456      ['zero_padding2d_7[0][0]']       \n",
      "                                                                                                  \n",
      " stage2_unit1_sc (Conv2D)       (None, 16, 16, 128)  8192        ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 16, 16, 128)  0           ['stage2_unit1_conv2[0][0]',     \n",
      "                                                                  'stage2_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage2_unit2_bn1 (BatchNormali  (None, 16, 16, 128)  512        ['add_2[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu1 (Activation  (None, 16, 16, 128)  0          ['stage2_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_8 (ZeroPadding2  (None, 18, 18, 128)  0          ['stage2_unit2_relu1[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit2_conv1 (Conv2D)    (None, 16, 16, 128)  147456      ['zero_padding2d_8[0][0]']       \n",
      "                                                                                                  \n",
      " stage2_unit2_bn2 (BatchNormali  (None, 16, 16, 128)  512        ['stage2_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu2 (Activation  (None, 16, 16, 128)  0          ['stage2_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_9 (ZeroPadding2  (None, 18, 18, 128)  0          ['stage2_unit2_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit2_conv2 (Conv2D)    (None, 16, 16, 128)  147456      ['zero_padding2d_9[0][0]']       \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 16, 16, 128)  0           ['stage2_unit2_conv2[0][0]',     \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " stage3_unit1_bn1 (BatchNormali  (None, 16, 16, 128)  512        ['add_3[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu1 (Activation  (None, 16, 16, 128)  0          ['stage3_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_10 (ZeroPadding  (None, 18, 18, 128)  0          ['stage3_unit1_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit1_conv1 (Conv2D)    (None, 8, 8, 256)    294912      ['zero_padding2d_10[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit1_bn2 (BatchNormali  (None, 8, 8, 256)   1024        ['stage3_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu2 (Activation  (None, 8, 8, 256)   0           ['stage3_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_11 (ZeroPadding  (None, 10, 10, 256)  0          ['stage3_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit1_conv2 (Conv2D)    (None, 8, 8, 256)    589824      ['zero_padding2d_11[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit1_sc (Conv2D)       (None, 8, 8, 256)    32768       ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 8, 8, 256)    0           ['stage3_unit1_conv2[0][0]',     \n",
      "                                                                  'stage3_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage3_unit2_bn1 (BatchNormali  (None, 8, 8, 256)   1024        ['add_4[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu1 (Activation  (None, 8, 8, 256)   0           ['stage3_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_12 (ZeroPadding  (None, 10, 10, 256)  0          ['stage3_unit2_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit2_conv1 (Conv2D)    (None, 8, 8, 256)    589824      ['zero_padding2d_12[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit2_bn2 (BatchNormali  (None, 8, 8, 256)   1024        ['stage3_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu2 (Activation  (None, 8, 8, 256)   0           ['stage3_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_13 (ZeroPadding  (None, 10, 10, 256)  0          ['stage3_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit2_conv2 (Conv2D)    (None, 8, 8, 256)    589824      ['zero_padding2d_13[0][0]']      \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 8, 256)    0           ['stage3_unit2_conv2[0][0]',     \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " stage4_unit1_bn1 (BatchNormali  (None, 8, 8, 256)   1024        ['add_5[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu1 (Activation  (None, 8, 8, 256)   0           ['stage4_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_14 (ZeroPadding  (None, 10, 10, 256)  0          ['stage4_unit1_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit1_conv1 (Conv2D)    (None, 4, 4, 512)    1179648     ['zero_padding2d_14[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit1_bn2 (BatchNormali  (None, 4, 4, 512)   2048        ['stage4_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu2 (Activation  (None, 4, 4, 512)   0           ['stage4_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_15 (ZeroPadding  (None, 6, 6, 512)   0           ['stage4_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit1_conv2 (Conv2D)    (None, 4, 4, 512)    2359296     ['zero_padding2d_15[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit1_sc (Conv2D)       (None, 4, 4, 512)    131072      ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 4, 4, 512)    0           ['stage4_unit1_conv2[0][0]',     \n",
      "                                                                  'stage4_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage4_unit2_bn1 (BatchNormali  (None, 4, 4, 512)   2048        ['add_6[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu1 (Activation  (None, 4, 4, 512)   0           ['stage4_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_16 (ZeroPadding  (None, 6, 6, 512)   0           ['stage4_unit2_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit2_conv1 (Conv2D)    (None, 4, 4, 512)    2359296     ['zero_padding2d_16[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit2_bn2 (BatchNormali  (None, 4, 4, 512)   2048        ['stage4_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu2 (Activation  (None, 4, 4, 512)   0           ['stage4_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_17 (ZeroPadding  (None, 6, 6, 512)   0           ['stage4_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit2_conv2 (Conv2D)    (None, 4, 4, 512)    2359296     ['zero_padding2d_17[0][0]']      \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 4, 4, 512)    0           ['stage4_unit2_conv2[0][0]',     \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 4, 4, 512)    2048        ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 4, 4, 512)    0           ['bn1[0][0]']                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['relu1[0][0]']                  \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          262656      ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           32832       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            66          ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " independent_normal (Independen  ((None, 1),         0           ['dense_3[0][0]']                \n",
      " tNormal)                        (None, 1))                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,484,523\n",
      "Trainable params: 11,476,581\n",
      "Non-trainable params: 7,942\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# See a sumary of the model with all the layers and parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from  19  files\n",
      "Total number of images:  460\n"
     ]
    }
   ],
   "source": [
    "# Collect all the .npz files\n",
    "numpy_datasets = glob.glob(data_dir+'dataset*')[1::2]\n",
    "\n",
    "# load the data into a dictionary from npz files\n",
    "data_dict = {}\n",
    "for dataset in numpy_datasets:\n",
    "    with np.load(dataset) as data:\n",
    "        if 'y' in data_dict.keys():\n",
    "            #data_dict['x_dust']   = np.append( data_dict['x_dust'], data['x_dust'],axis=0)\n",
    "            data_dict['x_nodust'] = np.append( data_dict['x_nodust'], data['x_nodust'],axis=0)\n",
    "            data_dict['y']        = np.append( data_dict['y'], data['y'],axis=0)\n",
    "            data_dict['ids']      = np.append( data_dict['ids'], data['id'],axis=0)\n",
    "            # data_dict['mass']      = np.append( data_dict['mass'], data['mass'],axis=0)\n",
    "            # data_dict['star_mass']      = np.append( data_dict['star_mass'], data['star_mass'],axis=0)\n",
    "        else:\n",
    "            #data_dict['x_dust']   = data['x_dust']\n",
    "            data_dict['x_nodust'] = data['x_nodust']\n",
    "            data_dict['y']        = data['y']\n",
    "            data_dict['ids']      = data['id']\n",
    "            # data_dict['mass']      = data['mass']\n",
    "            # data_dict['star_mass']      = data['star_mass']\n",
    "\n",
    "print('Loaded data from ', len(numpy_datasets), ' files')\n",
    "print('Total number of images: ', len(data_dict['x_nodust']))\n",
    "data_dict['ids'] = np.array(data_dict['ids'], dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  113  galaxies to remove\n",
      "Still have  347  galaxies left\n"
     ]
    }
   ],
   "source": [
    "# Filter the galaxies that have less than 1e10 solar masses or completely\n",
    "# black images\n",
    "a = np.amax(data_dict['x_nodust'], axis = (1,2,3))\n",
    "bad_ids = [[galaxy_id,i] for galaxy_id,i in zip(data_dict['ids'],range(len(data_dict['ids']))) if 'e09' in galaxy_id or a[i]<0.5]\n",
    "bad_ids = np.array(bad_ids)\n",
    "remove_galaxies = np.array(bad_ids[:,1],dtype=int)\n",
    "\n",
    "print('there are ', len(bad_ids), ' galaxies to remove')\n",
    "\n",
    "for key in data_dict.keys():\n",
    "    data_dict[key] = np.delete(data_dict[key],remove_galaxies, axis=0)\n",
    "    \n",
    "print('Still have ', len(data_dict['ids']), ' galaxies left')\n",
    "\n",
    "# Define dataset size and buffer size to use the whole dataset\n",
    "ds_size = len(data_dict['ids'])\n",
    "buf_size = 2*ds_size\n",
    "\n",
    "train_size = int(np.floor((1-validation_ratio)*ds_size))\n",
    "val_size = int(np.ceil(validation_ratio*ds_size))\n",
    "\n",
    "# Obtain names of unique galaxies in the dataset\n",
    "ALLuniqueids = data_dict['ids'].copy()\n",
    "for ii in range(np.size(data_dict['ids'])):\n",
    "    ALLuniqueids[ii] = data_dict['ids'][ii][:data_dict['ids'][ii].index('e')+3]\n",
    "uniqueids = np.unique(ALLuniqueids)\n",
    "\n",
    "train_uniqueids_num = int(np.floor((1-validation_ratio)*np.size(uniqueids)))\n",
    "val_uniqueids_num = int(np.ceil(validation_ratio*np.size(uniqueids)))\n",
    "\n",
    "# Generate random indexes to chose train and validation galaxies\n",
    "random.seed(rand_seed)\n",
    "randindexes = random.sample(range(np.size(uniqueids)), np.size(uniqueids))\n",
    "\n",
    "# Get masks to select training and validation samples\n",
    "train_mask = np.isin(ALLuniqueids, uniqueids[randindexes[:train_uniqueids_num]])\n",
    "val_mask = np.isin(ALLuniqueids, uniqueids[randindexes[train_uniqueids_num:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the normaliced vectors in 3D\n",
    "data_dict['y_norm'] = normalize(data_dict['y'], axis=1)\n",
    "\n",
    "# resize the images to the desired size\n",
    "data_dict['x_nodust'] = np.array([cv2.resize(img, (sizex, sizey), interpolation = cv2.INTER_AREA) for img in data_dict['x_nodust']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to do the augmentation\n",
    "\n",
    "# 50% Chance to flip an image left to right. If it does,\n",
    "# change the x component of angular momentum accordingly\n",
    "def random_flip_lr(image, label, seed=None):\n",
    "    img = tf.image.random_flip_left_right(image, seed=seed)\n",
    "    if tf.reduce_all(tf.equal(img,image)):\n",
    "        label_f = label\n",
    "    else:\n",
    "        label_f = tf.convert_to_tensor([-label[0],label[1]])\n",
    "    return (img, label_f)\n",
    "\n",
    "# 50% Chance to flip an image up to down. If it does,\n",
    "# change the y component of angular momentum accordingly\n",
    "def random_flip_ud(image, label, seed=None):\n",
    "    img = tf.image.random_flip_up_down(image, seed=seed)\n",
    "    if tf.reduce_all(tf.equal(img,image)):\n",
    "        label_f = label\n",
    "    else:\n",
    "        label_f = tf.convert_to_tensor([label[0],-label[1]])\n",
    "    return (img,label_f)\n",
    "\n",
    "# Rotate the image randomly, return the angle with respect to\n",
    "# x-axis as new label.\n",
    "def random_rot(image, label, seed=None):\n",
    "    \n",
    "    # Define the number of radians to rotate. 24 possible rotations\n",
    "    number_of_intervalls = 24\n",
    "    rad = tf.random.uniform(shape=[1], minval=0, maxval=2*math.pi, dtype=tf.float32)\n",
    "    rad = rad//(2*math.pi/number_of_intervalls) * (2*math.pi/number_of_intervalls)\n",
    "    \n",
    "    # Transform images\n",
    "    img = tfa.image.rotate(image, rad, interpolation = 'BILINEAR')\n",
    "    \n",
    "    # Transform J components\n",
    "    x = tf.math.multiply(tf.math.cos(-rad), label[0]) - tf.math.multiply(tf.math.sin(-rad), label[1])\n",
    "    y = tf.math.multiply(tf.math.sin(-rad), label[0]) + tf.math.multiply(tf.math.cos(-rad), label[1])\n",
    "    \n",
    "    # Obtain angle and restrict to quadrants 1 and 4\n",
    "    label_f = tf.math.atan2(y,x)*180/np.pi\n",
    "    if label_f > 90:\n",
    "        label_f-=180\n",
    "    if label_f <= -90:\n",
    "        label_f += 180\n",
    "        \n",
    "    # Renormalize: from -1 to 1\n",
    "    label_f = label_f / 90\n",
    "    \n",
    "    return (img,label_f)\n",
    "\n",
    "# Perform the three previous steps of augmentation\n",
    "def augment(img, label):\n",
    "    img_f,label_f = random_flip_lr(img,label)\n",
    "    img_f,label_f = random_flip_ud(img_f,label_f)\n",
    "    img_f,label_f = random_rot(img_f,label_f)\n",
    "    return (img_f, label_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set:\n",
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n",
      "Size = 69\n",
      "Training set:\n",
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n",
      "Size = 278\n"
     ]
    }
   ],
   "source": [
    "# MAKE DATASETS IN THE USUAL WAY\n",
    "\n",
    "# Import the autotune option from TF\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Defining the train and validation dataset from the existing dictionary, shufling and batching\n",
    "input_ds_nodust = (\n",
    "    tf.data.Dataset.from_tensor_slices((data_dict['x_nodust'].astype(np.float32),\n",
    "                                        data_dict['y_norm'][:,:2].astype(np.float32)))\n",
    "                    # Use seed to ensure we always have the same validation data set!\n",
    "                   .shuffle(ds_size, seed = rand_seed, reshuffle_each_iteration = False))\n",
    "\n",
    "# Compute the val_size dataset in terms of the ds_size and the validation_ratio that we have\n",
    "val_size = math.floor(ds_size * validation_ratio)\n",
    "\n",
    "# Cache and augment the dataset (THE ORDER IS IMPORTANT!!)\n",
    "validation_ds_nodust_aug =  (input_ds_nodust.take(val_size).cache()\n",
    "                            .map(augment, num_parallel_calls=AUTO))\n",
    "train_ds_nodust_aug      =  (input_ds_nodust.skip(val_size).cache()\n",
    "                            .map(augment, num_parallel_calls=AUTO))\n",
    "\n",
    "# If dust is activated compute the dust datasets\n",
    "if use_dust:\n",
    "    input_ds_dust = (\n",
    "        tf.data.Dataset.from_tensor_slices((data_dict['x_dust'].astype(np.float32),\n",
    "                                            data_dict['y_norm'][:,:2].astype(np.float32)))\n",
    "                       .shuffle(ds_size, seed = rand_seed, reshuffle_each_iteration = False))\n",
    "\n",
    "    input_ds_dust = input_ds_dust.take(ds_size)\n",
    "    validation_ds_dust_aug = (input_ds_dust.take(val_size).cache()\n",
    "                              .map(augment, num_parallel_calls=AUTO))\n",
    "    train_ds_dust_aug =  (input_ds_dust.skip(val_size).cache()\n",
    "                          .map(augment, num_parallel_calls=AUTO))\n",
    "\n",
    "    # concatenate both datasets (dust and no dust) and repeat the data and batch it\n",
    "    train_ds = (train_ds_dust_aug.concatenate(train_ds_nodust_aug)\n",
    "                    .shuffle(buffer_size=buf_size, reshuffle_each_iteration=True)\n",
    "                    .repeat(48).batch(batch_size).prefetch(AUTO))\n",
    "    validation_ds = (validation_ds_dust_aug.concatenate(validation_ds_nodust_aug)\n",
    "                    .repeat(48).batch(batch_size).prefetch(AUTO))\n",
    "\n",
    "else:\n",
    "    # If dust is not activated compute the dataset from the nodust dataset and reapeat the data and batch it\n",
    "    train_ds = (train_ds_nodust_aug\n",
    "                    .shuffle(buffer_size=buf_size, reshuffle_each_iteration=True)\n",
    "                    .repeat(batch_size).batch(batch_size).prefetch(AUTO))\n",
    "    validation_ds = (validation_ds_nodust_aug\n",
    "                    .repeat(batch_size).batch(batch_size).prefetch(AUTO))\n",
    "\n",
    "# Check all the datasets to see if they are correct\n",
    "print(\"Validation set:\")\n",
    "print(validation_ds)\n",
    "print(\"Size = \" + str(tf.data.experimental.cardinality(validation_ds).numpy()))\n",
    "print(\"Training set:\")\n",
    "print(train_ds)\n",
    "print(\"Size = \" + str(tf.data.experimental.cardinality(train_ds).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set:\n",
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n",
      "Size = 68\n",
      "Training set:\n",
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n",
      "Size = 277\n"
     ]
    }
   ],
   "source": [
    "# MAKE DATASETS WITHOUT REPEATING GALAXIES\n",
    "\n",
    "# Import the autotune option from TF\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Defining the train and validation dataset from the existing dictionary, shufling and batching\n",
    "input_train_nodust = (\n",
    "    tf.data.Dataset.from_tensor_slices((data_dict['x_nodust'][train_mask].astype(np.float32),\n",
    "                                        data_dict['y_norm'][train_mask,:2].astype(np.float32)))\n",
    "                    # Use seed to ensure we always have the same validation data set!\n",
    "                   .shuffle(ds_size, seed = rand_seed, reshuffle_each_iteration = False))\n",
    "input_val_nodust = (\n",
    "    tf.data.Dataset.from_tensor_slices((data_dict['x_nodust'][val_mask].astype(np.float32),\n",
    "                                        data_dict['y_norm'][val_mask,:2].astype(np.float32)))\n",
    "                    # Use seed to ensure we always have the same validation data set!\n",
    "                   .shuffle(ds_size, seed = rand_seed, reshuffle_each_iteration = False))\n",
    "\n",
    "\n",
    "# Cache and augment the dataset (THE ORDER IS IMPORTANT!!)\n",
    "validation_ds_nodust_aug =  (input_val_nodust.take(val_size).cache()\n",
    "                            .map(augment, num_parallel_calls=AUTO))\n",
    "train_ds_nodust_aug      =  (input_train_nodust.take(train_size).cache()\n",
    "                            .map(augment, num_parallel_calls=AUTO))\n",
    "\n",
    "# If dust is activated compute the dust datasets\n",
    "if use_dust:\n",
    "    input_ds_dust = (\n",
    "        tf.data.Dataset.from_tensor_slices((data_dict['x_dust'].astype(np.float32),\n",
    "                                            data_dict['y_norm'][:,:2].astype(np.float32)))\n",
    "                       .shuffle(ds_size, seed = rand_seed, reshuffle_each_iteration = False))\n",
    "    \n",
    "    input_ds_dust = input_ds_dust.take(ds_size)\n",
    "    validation_ds_dust_aug = (input_ds_dust.take(val_size).cache()\n",
    "                              .map(augment, num_parallel_calls=AUTO))\n",
    "    train_ds_dust_aug =  (input_ds_dust.skip(val_size).cache()\n",
    "                          .map(augment, num_parallel_calls=AUTO))\n",
    "    \n",
    "    # concatenate both datasets (dust and no dust) and repeat the data and batch it\n",
    "    train_ds = (train_ds_dust_aug.concatenate(train_ds_nodust_aug)\n",
    "                    .shuffle(buffer_size=buf_size, reshuffle_each_iteration=True)\n",
    "                    .repeat(48).batch(batch_size).prefetch(AUTO))\n",
    "    validation_ds = (validation_ds_dust_aug.concatenate(validation_ds_nodust_aug)\n",
    "                    .repeat(48).batch(batch_size).prefetch(AUTO))\n",
    "\n",
    "else:\n",
    "    # If dust is not activated compute the dataset from the nodust dataset and reapeat the data and batch it\n",
    "    train_ds = (train_ds_nodust_aug\n",
    "                    .shuffle(buffer_size=buf_size, reshuffle_each_iteration=True)\n",
    "                    .repeat(batch_size).batch(batch_size).prefetch(AUTO))\n",
    "    validation_ds = (validation_ds_nodust_aug\n",
    "                    .repeat(batch_size).batch(batch_size).prefetch(AUTO))\n",
    "\n",
    "# Check all the datasets to see if they are correct\n",
    "print(\"Validation set:\")\n",
    "print(validation_ds)\n",
    "print(\"Size = \" + str(tf.data.experimental.cardinality(validation_ds).numpy()))\n",
    "print(\"Training set:\")\n",
    "print(train_ds)\n",
    "print(\"Size = \" + str(tf.data.experimental.cardinality(train_ds).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:56:38.380810: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-01-26 10:56:39.287787: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-01-26 10:56:39.288609: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-01-26 10:56:39.288628: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-01-26 10:56:39.289364: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-01-26 10:56:39.289416: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-1.png\n",
      "Saved ValidationFig-NoMix-2.png\n",
      "Saved ValidationFig-NoMix-3.png\n",
      "Saved ValidationFig-NoMix-4.png\n",
      "Saved ValidationFig-NoMix-5.png\n",
      "Saved ValidationFig-NoMix-6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-7.png\n",
      "Saved ValidationFig-NoMix-8.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-9.png\n",
      "Saved ValidationFig-NoMix-10.png\n",
      "Saved ValidationFig-NoMix-11.png\n",
      "Saved ValidationFig-NoMix-12.png\n",
      "Saved ValidationFig-NoMix-13.png\n",
      "Saved ValidationFig-NoMix-14.png\n",
      "Saved ValidationFig-NoMix-15.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-16.png\n",
      "Saved ValidationFig-NoMix-17.png\n",
      "Saved ValidationFig-NoMix-18.png\n",
      "Saved ValidationFig-NoMix-19.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-20.png\n",
      "Saved ValidationFig-NoMix-21.png\n",
      "Saved ValidationFig-NoMix-22.png\n",
      "Saved ValidationFig-NoMix-23.png\n",
      "Saved ValidationFig-NoMix-24.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-25.png\n",
      "Saved ValidationFig-NoMix-26.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-27.png\n",
      "Saved ValidationFig-NoMix-28.png\n",
      "Saved ValidationFig-NoMix-29.png\n",
      "Saved ValidationFig-NoMix-30.png\n",
      "Saved ValidationFig-NoMix-31.png\n",
      "Saved ValidationFig-NoMix-32.png\n",
      "Saved ValidationFig-NoMix-33.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-34.png\n",
      "Saved ValidationFig-NoMix-35.png\n",
      "Saved ValidationFig-NoMix-36.png\n",
      "Saved ValidationFig-NoMix-37.png\n",
      "Saved ValidationFig-NoMix-38.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-39.png\n",
      "Saved ValidationFig-NoMix-40.png\n",
      "Saved ValidationFig-NoMix-41.png\n",
      "Saved ValidationFig-NoMix-42.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-43.png\n",
      "Saved ValidationFig-NoMix-44.png\n",
      "Saved ValidationFig-NoMix-45.png\n",
      "Saved ValidationFig-NoMix-46.png\n",
      "Saved ValidationFig-NoMix-47.png\n",
      "Saved ValidationFig-NoMix-48.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-49.png\n",
      "Saved ValidationFig-NoMix-50.png\n",
      "Saved ValidationFig-NoMix-51.png\n",
      "Saved ValidationFig-NoMix-52.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-53.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-54.png\n",
      "Saved ValidationFig-NoMix-55.png\n",
      "Saved ValidationFig-NoMix-56.png\n",
      "Saved ValidationFig-NoMix-57.png\n",
      "Saved ValidationFig-NoMix-58.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ValidationFig-NoMix-59.png\n",
      "Saved ValidationFig-NoMix-60.png\n",
      "Saved ValidationFig-NoMix-61.png\n",
      "Saved ValidationFig-NoMix-62.png\n",
      "Saved ValidationFig-NoMix-63.png\n"
     ]
    }
   ],
   "source": [
    "# function to visualice the data \n",
    "def viz(img, angle, idx, id=None):\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(8,4))\n",
    "    pdf = model(tf.expand_dims(img,[0]))\n",
    "    predangle = float(pdf.mean())\n",
    "    angle = angle*90\n",
    "    predangle = predangle*90\n",
    "    im = ax[0].imshow(img, cmap='gray', vmin=0, vmax=255,origin='lower')\n",
    "    length = 5\n",
    "    ax[0].arrow(64,64,1.5*length * math.cos(math.radians(angle)),1.5*length * math.sin(math.radians(angle)), head_width=7, head_length=10, fc='r', ec='r')\n",
    "    ax[0].arrow(64,64,length * math.cos(math.radians(predangle)),length * math.sin(math.radians(predangle)), head_width=7, head_length=10, fc='g', ec='g')\n",
    "    \n",
    "    x = np.linspace(-1,1,1000)\n",
    "    prob = []\n",
    "    for jj in range(1000):\n",
    "        prob.append(10**pdf.log_prob(x[jj]))\n",
    "    ax[1].plot(x*90, prob, 'r', label = 'Predicted')\n",
    "    ax[1].axvline(angle, color = 'g', label = 'Label')\n",
    "    ax[1].set_xticks([-90,-60,-30,0,30,60,90])\n",
    "    ax[1].legend()\n",
    "    ax[1].set_label('Conter-Clockwise angle from E-W ()')\n",
    "\n",
    "    plt.savefig('ValidationFig-NoMix-'+str(idx)+'.png')\n",
    "    print('Saved '+ 'ValidationFig-NoMix-'+str(idx)+'.png')\n",
    "    plt.close()\n",
    "\n",
    "for idx in range(1,64):\n",
    "    elements = validation_ds.take(1)\n",
    "    for elem in elements:\n",
    "        viz(elem[0][idx], elem[1][idx], idx)#, elem['y_revs'][idx], id=elem['ids'][idx])\n",
    "    \n",
    "    \n",
    "\n",
    "# function to visualice the data \n",
    "def viz(img, label, index, id=None):\n",
    "    x = np.linspace(-1,1,1000)\n",
    "    pdf = model(tf.expand_dims(img,[0]))\n",
    "    prob = []\n",
    "    for jj in range(1000):\n",
    "        prob.append(10**pdf.log_prob(x[jj]))\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    ax.plot(x, prob)\n",
    "    plt.axvline(label)\n",
    "    fig.savefig('Trainfig-'+str(index)+'.png')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "\n",
    "# visualice the data\n",
    "for idx in range(1,10):\n",
    "    elements = train_ds.take(idx)\n",
    "    for elem in elements:\n",
    "        viz(elem[0][idx], elem[1][idx], idx)#, elem['y_revs'][idx], id=elem['ids'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:58:52.184174: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 279\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025TensorSliceDataset:15\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 128\n",
      "        }\n",
      "        dim {\n",
      "          size: 128\n",
      "        }\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 2\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.7695 - mean_absolute_error: 0.6162"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:59:35.676861: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 68\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025TensorSliceDataset:17\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 128\n",
      "        }\n",
      "        dim {\n",
      "          size: 128\n",
      "        }\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 2\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.85829, saving model to models/best_resnet18_bs64.hdf5\n",
      "\n",
      "Epoch 1: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 48s 147ms/step - loss: 0.7695 - mean_absolute_error: 0.6162 - val_loss: 0.8583 - val_mean_absolute_error: 0.6339 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.6400 - mean_absolute_error: 0.5499\n",
      "Epoch 2: val_loss improved from 0.85829 to 0.64805, saving model to models/best_resnet18_bs64.hdf5\n",
      "\n",
      "Epoch 2: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 44s 157ms/step - loss: 0.6400 - mean_absolute_error: 0.5499 - val_loss: 0.6480 - val_mean_absolute_error: 0.5612 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.5861 - mean_absolute_error: 0.5263\n",
      "Epoch 3: val_loss improved from 0.64805 to 0.64094, saving model to models/best_resnet18_bs64.hdf5\n",
      "\n",
      "Epoch 3: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 164ms/step - loss: 0.5861 - mean_absolute_error: 0.5263 - val_loss: 0.6409 - val_mean_absolute_error: 0.5906 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.5392 - mean_absolute_error: 0.5124\n",
      "Epoch 4: val_loss did not improve from 0.64094\n",
      "\n",
      "Epoch 4: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 149ms/step - loss: 0.5392 - mean_absolute_error: 0.5124 - val_loss: 0.7981 - val_mean_absolute_error: 0.5283 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.5202 - mean_absolute_error: 0.5139\n",
      "Epoch 5: val_loss improved from 0.64094 to 0.61961, saving model to models/best_resnet18_bs64.hdf5\n",
      "\n",
      "Epoch 5: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 166ms/step - loss: 0.5202 - mean_absolute_error: 0.5139 - val_loss: 0.6196 - val_mean_absolute_error: 0.5511 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.4938 - mean_absolute_error: 0.5090\n",
      "Epoch 6: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 6: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 153ms/step - loss: 0.4938 - mean_absolute_error: 0.5090 - val_loss: 0.7438 - val_mean_absolute_error: 0.6033 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.4998 - mean_absolute_error: 0.5039\n",
      "Epoch 7: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 7: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 165ms/step - loss: 0.4998 - mean_absolute_error: 0.5039 - val_loss: 0.9995 - val_mean_absolute_error: 0.4737 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.4437 - mean_absolute_error: 0.4898\n",
      "Epoch 8: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 8: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 154ms/step - loss: 0.4437 - mean_absolute_error: 0.4898 - val_loss: 1.0737 - val_mean_absolute_error: 0.4735 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.3881 - mean_absolute_error: 0.4710\n",
      "Epoch 9: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 9: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 47s 166ms/step - loss: 0.3881 - mean_absolute_error: 0.4710 - val_loss: 0.7000 - val_mean_absolute_error: 0.5193 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.3843 - mean_absolute_error: 0.4665\n",
      "Epoch 10: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 10: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 44s 156ms/step - loss: 0.3843 - mean_absolute_error: 0.4665 - val_loss: 1.0143 - val_mean_absolute_error: 0.4632 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.3499 - mean_absolute_error: 0.4620\n",
      "Epoch 11: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 11: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 164ms/step - loss: 0.3499 - mean_absolute_error: 0.4620 - val_loss: 0.9315 - val_mean_absolute_error: 0.5151 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.2870 - mean_absolute_error: 0.4369\n",
      "Epoch 12: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 12: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 153ms/step - loss: 0.2870 - mean_absolute_error: 0.4369 - val_loss: 0.8348 - val_mean_absolute_error: 0.4847 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.2492 - mean_absolute_error: 0.4264\n",
      "Epoch 13: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 13: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 164ms/step - loss: 0.2492 - mean_absolute_error: 0.4264 - val_loss: 0.9677 - val_mean_absolute_error: 0.5071 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.2118 - mean_absolute_error: 0.4080\n",
      "Epoch 14: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 14: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 154ms/step - loss: 0.2118 - mean_absolute_error: 0.4080 - val_loss: 1.2981 - val_mean_absolute_error: 0.4757 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.1636 - mean_absolute_error: 0.3917\n",
      "Epoch 15: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 15: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 163ms/step - loss: 0.1636 - mean_absolute_error: 0.3917 - val_loss: 1.4908 - val_mean_absolute_error: 0.4501 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.2607 - mean_absolute_error: 0.4209\n",
      "Epoch 16: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 16: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 155ms/step - loss: 0.2607 - mean_absolute_error: 0.4209 - val_loss: 1.2338 - val_mean_absolute_error: 0.5161 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.1596 - mean_absolute_error: 0.3897\n",
      "Epoch 17: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 17: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 164ms/step - loss: 0.1596 - mean_absolute_error: 0.3897 - val_loss: 1.2020 - val_mean_absolute_error: 0.4542 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.0985 - mean_absolute_error: 0.3764\n",
      "Epoch 18: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 18: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 153ms/step - loss: 0.0985 - mean_absolute_error: 0.3764 - val_loss: 1.9542 - val_mean_absolute_error: 0.4525 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.0984 - mean_absolute_error: 0.3726\n",
      "Epoch 19: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 19: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 165ms/step - loss: 0.0984 - mean_absolute_error: 0.3726 - val_loss: 2.5223 - val_mean_absolute_error: 0.5326 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "277/277 [==============================] - ETA: 0s - loss: 0.0777 - mean_absolute_error: 0.3596\n",
      "Epoch 20: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 20: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 164ms/step - loss: 0.0777 - mean_absolute_error: 0.3596 - val_loss: 2.3951 - val_mean_absolute_error: 0.4335 - lr: 0.0100\n",
      "Updated learning rate to 0.006666666517655055\n",
      "Epoch 21/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.0543 - mean_absolute_error: 0.3195\n",
      "Epoch 21: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 21: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 149ms/step - loss: -0.0543 - mean_absolute_error: 0.3195 - val_loss: 2.0064 - val_mean_absolute_error: 0.4332 - lr: 0.0067\n",
      "Epoch 22/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.1123 - mean_absolute_error: 0.3010\n",
      "Epoch 22: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 22: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 151ms/step - loss: -0.1123 - mean_absolute_error: 0.3010 - val_loss: 2.4426 - val_mean_absolute_error: 0.4708 - lr: 0.0067\n",
      "Epoch 23/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.1326 - mean_absolute_error: 0.2943\n",
      "Epoch 23: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 23: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 162ms/step - loss: -0.1326 - mean_absolute_error: 0.2943 - val_loss: 1.8888 - val_mean_absolute_error: 0.4669 - lr: 0.0067\n",
      "Epoch 24/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.1636 - mean_absolute_error: 0.2888\n",
      "Epoch 24: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 24: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 150ms/step - loss: -0.1636 - mean_absolute_error: 0.2888 - val_loss: 3.2515 - val_mean_absolute_error: 0.4727 - lr: 0.0067\n",
      "Epoch 25/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.1860 - mean_absolute_error: 0.2817\n",
      "Epoch 25: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 25: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 150ms/step - loss: -0.1860 - mean_absolute_error: 0.2817 - val_loss: 2.1003 - val_mean_absolute_error: 0.4151 - lr: 0.0067\n",
      "Epoch 26/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.2016 - mean_absolute_error: 0.2820\n",
      "Epoch 26: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 26: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 162ms/step - loss: -0.2016 - mean_absolute_error: 0.2820 - val_loss: 2.2255 - val_mean_absolute_error: 0.4553 - lr: 0.0067\n",
      "Epoch 27/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.2067 - mean_absolute_error: 0.2774\n",
      "Epoch 27: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 27: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 151ms/step - loss: -0.2067 - mean_absolute_error: 0.2774 - val_loss: 2.8632 - val_mean_absolute_error: 0.4564 - lr: 0.0067\n",
      "Epoch 28/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.2378 - mean_absolute_error: 0.2716\n",
      "Epoch 28: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 28: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 152ms/step - loss: -0.2378 - mean_absolute_error: 0.2716 - val_loss: 1.9167 - val_mean_absolute_error: 0.4465 - lr: 0.0067\n",
      "Epoch 29/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.2699 - mean_absolute_error: 0.2638\n",
      "Epoch 29: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 29: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 163ms/step - loss: -0.2699 - mean_absolute_error: 0.2638 - val_loss: 2.7284 - val_mean_absolute_error: 0.4254 - lr: 0.0067\n",
      "Epoch 30/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.2754 - mean_absolute_error: 0.2574\n",
      "Epoch 30: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 30: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 147ms/step - loss: -0.2754 - mean_absolute_error: 0.2574 - val_loss: 2.5695 - val_mean_absolute_error: 0.4276 - lr: 0.0067\n",
      "Epoch 31/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.2830 - mean_absolute_error: 0.2616\n",
      "Epoch 31: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 31: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 154ms/step - loss: -0.2830 - mean_absolute_error: 0.2616 - val_loss: 3.6161 - val_mean_absolute_error: 0.4099 - lr: 0.0067\n",
      "Epoch 32/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.2998 - mean_absolute_error: 0.2569\n",
      "Epoch 32: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 32: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 151ms/step - loss: -0.2998 - mean_absolute_error: 0.2569 - val_loss: 3.2464 - val_mean_absolute_error: 0.4239 - lr: 0.0067\n",
      "Epoch 33/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.3235 - mean_absolute_error: 0.2459\n",
      "Epoch 33: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 33: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 163ms/step - loss: -0.3235 - mean_absolute_error: 0.2459 - val_loss: 3.0234 - val_mean_absolute_error: 0.4552 - lr: 0.0067\n",
      "Epoch 34/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.3487 - mean_absolute_error: 0.2458\n",
      "Epoch 34: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 34: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 148ms/step - loss: -0.3487 - mean_absolute_error: 0.2458 - val_loss: 4.1058 - val_mean_absolute_error: 0.4198 - lr: 0.0067\n",
      "Epoch 35/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.3767 - mean_absolute_error: 0.2358\n",
      "Epoch 35: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 35: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 152ms/step - loss: -0.3767 - mean_absolute_error: 0.2358 - val_loss: 3.9385 - val_mean_absolute_error: 0.4300 - lr: 0.0067\n",
      "Epoch 36/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.3510 - mean_absolute_error: 0.2473\n",
      "Epoch 36: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 36: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 165ms/step - loss: -0.3510 - mean_absolute_error: 0.2473 - val_loss: 3.0171 - val_mean_absolute_error: 0.4241 - lr: 0.0067\n",
      "Epoch 37/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.3508 - mean_absolute_error: 0.2455\n",
      "Epoch 37: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 37: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 151ms/step - loss: -0.3508 - mean_absolute_error: 0.2455 - val_loss: 2.5203 - val_mean_absolute_error: 0.4455 - lr: 0.0067\n",
      "Epoch 38/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.3957 - mean_absolute_error: 0.2332\n",
      "Epoch 38: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 38: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 152ms/step - loss: -0.3957 - mean_absolute_error: 0.2332 - val_loss: 3.3629 - val_mean_absolute_error: 0.4478 - lr: 0.0067\n",
      "Epoch 39/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.4186 - mean_absolute_error: 0.2296\n",
      "Epoch 39: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 39: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 164ms/step - loss: -0.4186 - mean_absolute_error: 0.2296 - val_loss: 3.4993 - val_mean_absolute_error: 0.4268 - lr: 0.0067\n",
      "Epoch 40/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.3577 - mean_absolute_error: 0.2463\n",
      "Epoch 40: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 40: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 148ms/step - loss: -0.3577 - mean_absolute_error: 0.2463 - val_loss: 4.1429 - val_mean_absolute_error: 0.4221 - lr: 0.0067\n",
      "Updated learning rate to 0.004444444241623084\n",
      "Epoch 41/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.5149 - mean_absolute_error: 0.2140\n",
      "Epoch 41: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 41: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 154ms/step - loss: -0.5149 - mean_absolute_error: 0.2140 - val_loss: 5.2284 - val_mean_absolute_error: 0.4049 - lr: 0.0044\n",
      "Epoch 42/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.5506 - mean_absolute_error: 0.2041\n",
      "Epoch 42: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 42: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 164ms/step - loss: -0.5506 - mean_absolute_error: 0.2041 - val_loss: 5.5342 - val_mean_absolute_error: 0.4029 - lr: 0.0044\n",
      "Epoch 43/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.5818 - mean_absolute_error: 0.2027\n",
      "Epoch 43: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 43: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 148ms/step - loss: -0.5818 - mean_absolute_error: 0.2027 - val_loss: 4.9174 - val_mean_absolute_error: 0.4042 - lr: 0.0044\n",
      "Epoch 44/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.5549 - mean_absolute_error: 0.2014\n",
      "Epoch 44: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 44: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 44s 156ms/step - loss: -0.5549 - mean_absolute_error: 0.2014 - val_loss: 4.8739 - val_mean_absolute_error: 0.4144 - lr: 0.0044\n",
      "Epoch 45/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.5893 - mean_absolute_error: 0.1969\n",
      "Epoch 45: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 45: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 152ms/step - loss: -0.5893 - mean_absolute_error: 0.1969 - val_loss: 5.1268 - val_mean_absolute_error: 0.4179 - lr: 0.0044\n",
      "Epoch 46/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6159 - mean_absolute_error: 0.1900\n",
      "Epoch 46: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 46: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 164ms/step - loss: -0.6159 - mean_absolute_error: 0.1900 - val_loss: 6.7826 - val_mean_absolute_error: 0.4014 - lr: 0.0044\n",
      "Epoch 47/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.5086 - mean_absolute_error: 0.2127\n",
      "Epoch 47: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 47: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 149ms/step - loss: -0.5086 - mean_absolute_error: 0.2127 - val_loss: 5.6303 - val_mean_absolute_error: 0.3987 - lr: 0.0044\n",
      "Epoch 48/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.5902 - mean_absolute_error: 0.1958\n",
      "Epoch 48: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 48: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 153ms/step - loss: -0.5902 - mean_absolute_error: 0.1958 - val_loss: 6.4308 - val_mean_absolute_error: 0.4342 - lr: 0.0044\n",
      "Epoch 49/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6101 - mean_absolute_error: 0.1933\n",
      "Epoch 49: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 49: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 161ms/step - loss: -0.6101 - mean_absolute_error: 0.1933 - val_loss: 5.6813 - val_mean_absolute_error: 0.4116 - lr: 0.0044\n",
      "Epoch 50/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6323 - mean_absolute_error: 0.1904\n",
      "Epoch 50: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 50: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 147ms/step - loss: -0.6323 - mean_absolute_error: 0.1904 - val_loss: 5.8906 - val_mean_absolute_error: 0.4258 - lr: 0.0044\n",
      "Epoch 51/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6294 - mean_absolute_error: 0.1872\n",
      "Epoch 51: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 51: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 154ms/step - loss: -0.6294 - mean_absolute_error: 0.1872 - val_loss: 7.7294 - val_mean_absolute_error: 0.3973 - lr: 0.0044\n",
      "Epoch 52/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.5487 - mean_absolute_error: 0.2058\n",
      "Epoch 52: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 52: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 164ms/step - loss: -0.5487 - mean_absolute_error: 0.2058 - val_loss: 5.8090 - val_mean_absolute_error: 0.4170 - lr: 0.0044\n",
      "Epoch 53/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6421 - mean_absolute_error: 0.1830\n",
      "Epoch 53: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 53: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 148ms/step - loss: -0.6421 - mean_absolute_error: 0.1830 - val_loss: 7.1034 - val_mean_absolute_error: 0.4240 - lr: 0.0044\n",
      "Epoch 54/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6538 - mean_absolute_error: 0.1880\n",
      "Epoch 54: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 54: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 154ms/step - loss: -0.6538 - mean_absolute_error: 0.1880 - val_loss: 6.7003 - val_mean_absolute_error: 0.4123 - lr: 0.0044\n",
      "Epoch 55/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6519 - mean_absolute_error: 0.1861\n",
      "Epoch 55: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 55: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 162ms/step - loss: -0.6519 - mean_absolute_error: 0.1861 - val_loss: 6.3252 - val_mean_absolute_error: 0.4322 - lr: 0.0044\n",
      "Epoch 56/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6227 - mean_absolute_error: 0.1916\n",
      "Epoch 56: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 56: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 149ms/step - loss: -0.6227 - mean_absolute_error: 0.1916 - val_loss: 7.6170 - val_mean_absolute_error: 0.4125 - lr: 0.0044\n",
      "Epoch 57/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6586 - mean_absolute_error: 0.1822\n",
      "Epoch 57: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 57: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 155ms/step - loss: -0.6586 - mean_absolute_error: 0.1822 - val_loss: 6.9650 - val_mean_absolute_error: 0.4102 - lr: 0.0044\n",
      "Epoch 58/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6961 - mean_absolute_error: 0.1785\n",
      "Epoch 58: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 58: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 163ms/step - loss: -0.6961 - mean_absolute_error: 0.1785 - val_loss: 6.9617 - val_mean_absolute_error: 0.4370 - lr: 0.0044\n",
      "Epoch 59/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6745 - mean_absolute_error: 0.1794\n",
      "Epoch 59: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 59: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 148ms/step - loss: -0.6745 - mean_absolute_error: 0.1794 - val_loss: 7.5003 - val_mean_absolute_error: 0.4028 - lr: 0.0044\n",
      "Epoch 60/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.6886 - mean_absolute_error: 0.1811\n",
      "Epoch 60: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 60: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 44s 159ms/step - loss: -0.6886 - mean_absolute_error: 0.1811 - val_loss: 9.0736 - val_mean_absolute_error: 0.4152 - lr: 0.0044\n",
      "Updated learning rate to 0.0029629627242684364\n",
      "Epoch 61/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.7627 - mean_absolute_error: 0.1718\n",
      "Epoch 61: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 61: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 44s 156ms/step - loss: -0.7627 - mean_absolute_error: 0.1718 - val_loss: 8.5794 - val_mean_absolute_error: 0.3961 - lr: 0.0030\n",
      "Epoch 62/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.7698 - mean_absolute_error: 0.1680\n",
      "Epoch 62: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 62: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 48s 170ms/step - loss: -0.7698 - mean_absolute_error: 0.1680 - val_loss: 8.3164 - val_mean_absolute_error: 0.4259 - lr: 0.0030\n",
      "Epoch 63/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.7721 - mean_absolute_error: 0.1653\n",
      "Epoch 63: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 63: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 152ms/step - loss: -0.7721 - mean_absolute_error: 0.1653 - val_loss: 8.6989 - val_mean_absolute_error: 0.4075 - lr: 0.0030\n",
      "Epoch 64/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8002 - mean_absolute_error: 0.1617\n",
      "Epoch 64: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 64: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 154ms/step - loss: -0.8002 - mean_absolute_error: 0.1617 - val_loss: 9.3312 - val_mean_absolute_error: 0.4200 - lr: 0.0030\n",
      "Epoch 65/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.7980 - mean_absolute_error: 0.1632\n",
      "Epoch 65: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 65: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 47s 170ms/step - loss: -0.7980 - mean_absolute_error: 0.1632 - val_loss: 10.6307 - val_mean_absolute_error: 0.3970 - lr: 0.0030\n",
      "Epoch 66/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8103 - mean_absolute_error: 0.1586\n",
      "Epoch 66: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 66: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 44s 155ms/step - loss: -0.8103 - mean_absolute_error: 0.1586 - val_loss: 9.2507 - val_mean_absolute_error: 0.4156 - lr: 0.0030\n",
      "Epoch 67/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8225 - mean_absolute_error: 0.1597\n",
      "Epoch 67: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 67: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 44s 158ms/step - loss: -0.8225 - mean_absolute_error: 0.1597 - val_loss: 9.3424 - val_mean_absolute_error: 0.4031 - lr: 0.0030\n",
      "Epoch 68/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8134 - mean_absolute_error: 0.1575\n",
      "Epoch 68: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 68: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 162ms/step - loss: -0.8134 - mean_absolute_error: 0.1575 - val_loss: 9.5008 - val_mean_absolute_error: 0.4048 - lr: 0.0030\n",
      "Epoch 69/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8226 - mean_absolute_error: 0.1564\n",
      "Epoch 69: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 69: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 148ms/step - loss: -0.8226 - mean_absolute_error: 0.1564 - val_loss: 10.4190 - val_mean_absolute_error: 0.3960 - lr: 0.0030\n",
      "Epoch 70/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8106 - mean_absolute_error: 0.1590\n",
      "Epoch 70: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 70: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 44s 159ms/step - loss: -0.8106 - mean_absolute_error: 0.1590 - val_loss: 9.4833 - val_mean_absolute_error: 0.4101 - lr: 0.0030\n",
      "Epoch 71/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8223 - mean_absolute_error: 0.1582\n",
      "Epoch 71: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 71: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 162ms/step - loss: -0.8223 - mean_absolute_error: 0.1582 - val_loss: 10.2361 - val_mean_absolute_error: 0.4126 - lr: 0.0030\n",
      "Epoch 72/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8456 - mean_absolute_error: 0.1568\n",
      "Epoch 72: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 72: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 147ms/step - loss: -0.8456 - mean_absolute_error: 0.1568 - val_loss: 10.0030 - val_mean_absolute_error: 0.3999 - lr: 0.0030\n",
      "Epoch 73/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8443 - mean_absolute_error: 0.1550\n",
      "Epoch 73: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 73: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 155ms/step - loss: -0.8443 - mean_absolute_error: 0.1550 - val_loss: 11.1417 - val_mean_absolute_error: 0.3906 - lr: 0.0030\n",
      "Epoch 74/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8467 - mean_absolute_error: 0.1548\n",
      "Epoch 74: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 74: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 162ms/step - loss: -0.8467 - mean_absolute_error: 0.1548 - val_loss: 11.5994 - val_mean_absolute_error: 0.3906 - lr: 0.0030\n",
      "Epoch 75/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8484 - mean_absolute_error: 0.1538\n",
      "Epoch 75: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 75: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 152ms/step - loss: -0.8484 - mean_absolute_error: 0.1538 - val_loss: 9.8723 - val_mean_absolute_error: 0.3911 - lr: 0.0030\n",
      "Epoch 76/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8270 - mean_absolute_error: 0.1615\n",
      "Epoch 76: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 76: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 155ms/step - loss: -0.8270 - mean_absolute_error: 0.1615 - val_loss: 10.2161 - val_mean_absolute_error: 0.4037 - lr: 0.0030\n",
      "Epoch 77/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8388 - mean_absolute_error: 0.1540\n",
      "Epoch 77: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 77: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 162ms/step - loss: -0.8388 - mean_absolute_error: 0.1540 - val_loss: 9.9949 - val_mean_absolute_error: 0.4063 - lr: 0.0030\n",
      "Epoch 78/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8497 - mean_absolute_error: 0.1538\n",
      "Epoch 78: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 78: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 152ms/step - loss: -0.8497 - mean_absolute_error: 0.1538 - val_loss: 10.5147 - val_mean_absolute_error: 0.4154 - lr: 0.0030\n",
      "Epoch 79/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8524 - mean_absolute_error: 0.1520\n",
      "Epoch 79: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 79: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 155ms/step - loss: -0.8524 - mean_absolute_error: 0.1520 - val_loss: 10.5920 - val_mean_absolute_error: 0.4063 - lr: 0.0030\n",
      "Epoch 80/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.8603 - mean_absolute_error: 0.1544\n",
      "Epoch 80: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 80: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 164ms/step - loss: -0.8603 - mean_absolute_error: 0.1544 - val_loss: 10.6953 - val_mean_absolute_error: 0.4134 - lr: 0.0030\n",
      "Updated learning rate to 0.0019753084828456244\n",
      "Epoch 81/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9132 - mean_absolute_error: 0.1469\n",
      "Epoch 81: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 81: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 148ms/step - loss: -0.9132 - mean_absolute_error: 0.1469 - val_loss: 11.9334 - val_mean_absolute_error: 0.4065 - lr: 0.0020\n",
      "Epoch 82/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9127 - mean_absolute_error: 0.1427\n",
      "Epoch 82: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 82: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 44s 156ms/step - loss: -0.9127 - mean_absolute_error: 0.1427 - val_loss: 11.2134 - val_mean_absolute_error: 0.4119 - lr: 0.0020\n",
      "Epoch 83/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9360 - mean_absolute_error: 0.1419\n",
      "Epoch 83: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 83: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 163ms/step - loss: -0.9360 - mean_absolute_error: 0.1419 - val_loss: 12.5511 - val_mean_absolute_error: 0.4018 - lr: 0.0020\n",
      "Epoch 84/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9341 - mean_absolute_error: 0.1421\n",
      "Epoch 84: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 84: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 148ms/step - loss: -0.9341 - mean_absolute_error: 0.1421 - val_loss: 12.0346 - val_mean_absolute_error: 0.4100 - lr: 0.0020\n",
      "Epoch 85/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9390 - mean_absolute_error: 0.1404\n",
      "Epoch 85: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 85: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 44s 157ms/step - loss: -0.9390 - mean_absolute_error: 0.1404 - val_loss: 12.3162 - val_mean_absolute_error: 0.4050 - lr: 0.0020\n",
      "Epoch 86/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9443 - mean_absolute_error: 0.1393\n",
      "Epoch 86: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 86: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 163ms/step - loss: -0.9443 - mean_absolute_error: 0.1393 - val_loss: 13.6339 - val_mean_absolute_error: 0.4020 - lr: 0.0020\n",
      "Epoch 87/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9563 - mean_absolute_error: 0.1385\n",
      "Epoch 87: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 87: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 155ms/step - loss: -0.9563 - mean_absolute_error: 0.1385 - val_loss: 12.1524 - val_mean_absolute_error: 0.4109 - lr: 0.0020\n",
      "Epoch 88/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9482 - mean_absolute_error: 0.1396\n",
      "Epoch 88: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 88: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 154ms/step - loss: -0.9482 - mean_absolute_error: 0.1396 - val_loss: 13.0191 - val_mean_absolute_error: 0.4120 - lr: 0.0020\n",
      "Epoch 89/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9547 - mean_absolute_error: 0.1390\n",
      "Epoch 89: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 89: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 46s 164ms/step - loss: -0.9547 - mean_absolute_error: 0.1390 - val_loss: 12.4003 - val_mean_absolute_error: 0.4095 - lr: 0.0020\n",
      "Epoch 90/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9394 - mean_absolute_error: 0.1420\n",
      "Epoch 90: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 90: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 149ms/step - loss: -0.9394 - mean_absolute_error: 0.1420 - val_loss: 12.1652 - val_mean_absolute_error: 0.4177 - lr: 0.0020\n",
      "Epoch 91/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9641 - mean_absolute_error: 0.1365\n",
      "Epoch 91: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 91: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 44s 157ms/step - loss: -0.9641 - mean_absolute_error: 0.1365 - val_loss: 15.0694 - val_mean_absolute_error: 0.4085 - lr: 0.0020\n",
      "Epoch 92/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9703 - mean_absolute_error: 0.1356\n",
      "Epoch 92: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 92: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 162ms/step - loss: -0.9703 - mean_absolute_error: 0.1356 - val_loss: 13.8401 - val_mean_absolute_error: 0.4096 - lr: 0.0020\n",
      "Epoch 93/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9783 - mean_absolute_error: 0.1360\n",
      "Epoch 93: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 93: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 42s 149ms/step - loss: -0.9783 - mean_absolute_error: 0.1360 - val_loss: 15.1269 - val_mean_absolute_error: 0.4076 - lr: 0.0020\n",
      "Epoch 94/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9658 - mean_absolute_error: 0.1377\n",
      "Epoch 94: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 94: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 154ms/step - loss: -0.9658 - mean_absolute_error: 0.1377 - val_loss: 12.0023 - val_mean_absolute_error: 0.4089 - lr: 0.0020\n",
      "Epoch 95/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9587 - mean_absolute_error: 0.1391\n",
      "Epoch 95: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 95: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 160ms/step - loss: -0.9587 - mean_absolute_error: 0.1391 - val_loss: 13.9127 - val_mean_absolute_error: 0.4034 - lr: 0.0020\n",
      "Epoch 96/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9843 - mean_absolute_error: 0.1331\n",
      "Epoch 96: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 96: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 41s 148ms/step - loss: -0.9843 - mean_absolute_error: 0.1331 - val_loss: 13.7891 - val_mean_absolute_error: 0.4167 - lr: 0.0020\n",
      "Epoch 97/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9754 - mean_absolute_error: 0.1357\n",
      "Epoch 97: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 97: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 154ms/step - loss: -0.9754 - mean_absolute_error: 0.1357 - val_loss: 13.3499 - val_mean_absolute_error: 0.3973 - lr: 0.0020\n",
      "Epoch 98/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9612 - mean_absolute_error: 0.1361\n",
      "Epoch 98: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 98: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 45s 160ms/step - loss: -0.9612 - mean_absolute_error: 0.1361 - val_loss: 13.8477 - val_mean_absolute_error: 0.4095 - lr: 0.0020\n",
      "Epoch 99/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9732 - mean_absolute_error: 0.1366\n",
      "Epoch 99: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 99: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 40s 145ms/step - loss: -0.9732 - mean_absolute_error: 0.1366 - val_loss: 14.1550 - val_mean_absolute_error: 0.3986 - lr: 0.0020\n",
      "Epoch 100/100\n",
      "277/277 [==============================] - ETA: 0s - loss: -0.9818 - mean_absolute_error: 0.1336\n",
      "Epoch 100: val_loss did not improve from 0.61961\n",
      "\n",
      "Epoch 100: saving model to models/last_resnet18_bs64.hdf5\n",
      "277/277 [==============================] - 43s 154ms/step - loss: -0.9818 - mean_absolute_error: 0.1336 - val_loss: 13.3113 - val_mean_absolute_error: 0.4002 - lr: 0.0020\n"
     ]
    }
   ],
   "source": [
    "# For tensorboard to save the models\n",
    "log_dir_s = log_dir + model_name\n",
    "os.makedirs(log_dir_s, exist_ok=True)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir_s, histogram_freq=1, update_freq='batch', profile_batch=0)\n",
    "\n",
    "#Sefine the learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch!=0 and epoch%20==0:\n",
    "        print('Updated learning rate to '+str(lr/1.5))\n",
    "        return lr/1.5\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "\n",
    "# Checkpointing\n",
    "checkpointer_1 = tf.keras.callbacks.ModelCheckpoint(filepath=snapshot_weights,\n",
    "                               monitor='val_loss',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True)\n",
    "checkpointer_2 = tf.keras.callbacks.ModelCheckpoint(filepath=last_snapshot_weights,\n",
    "                               monitor='val_loss',\n",
    "                               verbose=1,\n",
    "                               save_best_only=False)\n",
    "LearningRateScheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "callbacks = [\n",
    "    tensorboard_callback,\n",
    "    checkpointer_1,\n",
    "    checkpointer_2,\n",
    "    LearningRateScheduler,\n",
    "]\n",
    "\n",
    "# Fit the model with the training and validation data, number of epochs and callbacks\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data = validation_ds,\n",
    "    epochs = nb_epochs,\n",
    "    callbacks = callbacks,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "plt.title('Mean Absolute Error')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('errMSE-NEW-NoMix.png')\n",
    "plt.close()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('lossMSE-NEW-NoMix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the last weights of the model\n",
    "model.save(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'models/best_resnet18_bs64.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# taking samples from the validation dataset and evaluating the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(snapshot_weights)\n\u001b[1;32m      3\u001b[0m val_ex, \u001b[39m=\u001b[39m validation_ds\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m train_ex, \u001b[39m=\u001b[39m train_ds\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/envs/miniconda3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/h5py/_hl/files.py:507\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds)\u001b[0m\n\u001b[1;32m    502\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    503\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    504\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[1;32m    505\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[1;32m    506\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 507\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39mswmr)\n\u001b[1;32m    509\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    510\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/h5py/_hl/files.py:220\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[1;32m    219\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 220\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[1;32m    221\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    222\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'models/best_resnet18_bs64.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# taking samples from the validation dataset and evaluating the model\n",
    "model.load_weights(snapshot_weights)\n",
    "val_ex, = validation_ds.take(1)\n",
    "train_ex, = train_ds.take(1)\n",
    "\n",
    "images_v, labels_v = val_ex[0], val_ex[1]\n",
    "images_t, labels_t = train_ex[0], train_ex[1]\n",
    "\n",
    "#making the predictions for the taken images\n",
    "outputs_v = model.predict(images_v)\n",
    "outputs_t = model.predict(images_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# visualicing the results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m img,label,pred,i \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(images_t, labels_t, outputs_t,\u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m)):\n\u001b[1;32m      3\u001b[0m     viz(img, label, pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images_t' is not defined"
     ]
    }
   ],
   "source": [
    "# visualicing the results\n",
    "for img,label,pred,i in zip(images_t, labels_t, outputs_t,range(5)):\n",
    "    viz(img, label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img,label,pred,i in zip(images_v, labels_v, outputs_v,range(5)):\n",
    "    viz(img, label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d14dbbbc27f17b30704aec684e90d307cbd8380a885ba3f31a6ea0af591ba061"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
